{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a364397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading tpdata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import esig\n",
    "tpdata=pd.read_csv(\"ADNI/tpdata.csv\",header=None)\n",
    "\n",
    "#Types :\n",
    "#AD->3\n",
    "#MCI->2\n",
    "#NL->1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8bfc348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Eliminating measurement of month 3 in AD people\n",
    "rows_ad=tpdata[tpdata[4]==3]\n",
    "rows_ad_with_month_equal_3=rows_ad[rows_ad[3]==3]\n",
    "tpdata.drop(rows_ad_with_month_equal_3.index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4195b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Sorting rows for each individual\n",
    "tpdata1=tpdata.iloc[:,0]\n",
    "values=set(tpdata1.values.flatten())\n",
    "for individual in values:\n",
    "    individual_index=np.where(tpdata.iloc[:,0]==individual)[0]\n",
    "    if len(individual_index)>0:\n",
    "        tpdata.iloc[individual_index].sort_values(by=3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Eliminating months excedding 24\n",
    "exceeding_months_indexes=np.where(tpdata[3]>24)[0]\n",
    "rows_exceeding=tpdata[tpdata[3]>24]\n",
    "tpdata.drop(rows_exceeding.index,inplace=True)\n",
    "\n",
    "\n",
    "#eliminating non classified people\n",
    "non_class_indexes=np.where(tpdata[4]==0)[0]\n",
    "rows_non_class=tpdata[tpdata[4]==0]\n",
    "tpdata.drop(rows_non_class.index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ec7f1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only the columns of: \n",
    "tpdata=tpdata.iloc[:,[0,4,5,21,22,33]]\n",
    "tpdata.columns=[\"Individual\", \"Type\",\"Measurement\",\"Hippocampal Volume\", \"Brain Volume\", \"Ventricle Volume\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2a3da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing values\n",
    "\n",
    "\n",
    "tpdata.iloc[:,3]=tpdata.iloc[:,3]/10000\n",
    "tpdata.iloc[:,5]=tpdata.iloc[:,5]/100000\n",
    "tpdata.iloc[:,4]=tpdata.iloc[:,4]/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "935f27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpdata=tpdata.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2dd1faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing measurements\n",
    "tpdata1=tpdata.iloc[:,0]\n",
    "values=set(tpdata.values.flatten())\n",
    "for individual in values:\n",
    "    individual_index=np.where(tpdata.iloc[:,0]==individual)[0]\n",
    "    if len(individual_index)>0:\n",
    "        tpdata.iloc[individual_index,2]=(tpdata.iloc[individual_index,2]-tpdata.iloc[individual_index[0],2])/30\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f236de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering only individuals with long time series\n",
    "big_individuals=[]\n",
    "for individual, individual_data in tpdata.groupby(\"Individual\"):\n",
    "    if len(individual_data)>3:\n",
    "        big_individuals.append(individual)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5fb3e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata=tpdata[tpdata[\"Individual\"].isin(big_individuals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43e59925",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "Feature_vectors_sig=list()\n",
    "for individual, individual_data in newdata.groupby(\"Individual\"):\n",
    "    individual_timeseries=individual_data.iloc[:,[2,3,4,5]].to_numpy()\n",
    "    individual_signature=esig.stream2sig(individual_timeseries,2)[1:]\n",
    "    individual_baseline=individual_timeseries[0][[1,2,3]]\n",
    "    individual_feature_vector=np.concatenate([individual_baseline,individual_signature])\n",
    "    individual_feature_vector[3:]=individual_feature_vector[3:]*10\n",
    "    individual_feature_vector[[0,1,2]]=individual_feature_vector[[0,1,2]]\n",
    "    Feature_vectors_sig.append(individual_feature_vector)\n",
    "    labels.append(individual_data.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e3520239",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_vectors_sig_matrix=np.array(Feature_vectors_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0021edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5676eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate data into train and test\n",
    "X_train, X_test, y_train, y_test=train_test_split(Feature_vectors_sig_matrix,labels,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ffa07ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5695067264573991"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on X_train\n",
    "clf=RandomForestClassifier().fit(X_train,y_train)\n",
    "\n",
    "#Predict Labels of X_test\n",
    "y_predicted=clf.predict(X_test)\n",
    "\n",
    "\n",
    "#Compare predicted labels with y\n",
    "accuracy_score(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1d7d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using log signature\n",
    "\n",
    "lab_log=[]\n",
    "Feature_vectors_log=list()\n",
    "for individual, individual_data in newdata.groupby(\"Individual\"):\n",
    "    individual_timeseries=individual_data.iloc[:,[2,3,4,5]].to_numpy()\n",
    "    individual_signature=esig.stream2logsig(individual_timeseries,2)\n",
    "    individual_baseline=individual_timeseries[0][[1,2,3]]\n",
    "    individual_feature_vector=np.concatenate([individual_baseline,individual_signature])\n",
    "    Feature_vectors_log.append(individual_feature_vector)\n",
    "    lab_log.append(individual_data.iloc[0,1])\n",
    "\n",
    "Feat_log=np.array(Feature_vectors_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d8bf93eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6518518518518519"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separate data into train and test\n",
    "X_train_log, X_test_log, y_train_log, y_test_log=train_test_split(Feat_log,lab_log,test_size=0.2)\n",
    "\n",
    "# Train model on X_train\n",
    "clf=RandomForestClassifier().fit(X_train_log,y_train_log)\n",
    "\n",
    "#Predict Labels of X_test\n",
    "y_predicted_log=clf.predict(X_test_log)\n",
    "\n",
    "\n",
    "#Compare predicted labels with y\n",
    "accuracy_score(y_test_log,y_predicted_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f299d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AD vs NL classification\n",
    "not2=[]\n",
    "for individual, individual_data in newdata.groupby(\"Individual\"):\n",
    "    if ( not (individual_data.iloc[:,1]==2).any()):\n",
    "        not2.append(individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d0ba9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata2=newdata[newdata[\"Individual\"].isin(not2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "678293d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2=[]\n",
    "Feature_vectors_sig2=list()\n",
    "for individual, individual_data in newdata2.groupby(\"Individual\"):\n",
    "    individual_timeseries=individual_data.iloc[:,[2,3,4,5]].to_numpy()\n",
    "    individual_signature=esig.stream2sig(individual_timeseries,2)[1:]\n",
    "    individual_baseline=individual_timeseries[0][[1,2,3]]\n",
    "    individual_feature_vector=np.concatenate([individual_baseline,individual_signature])\n",
    "    Feature_vectors_sig2.append(individual_feature_vector)\n",
    "    labels2.append(individual_data.iloc[0,1])\n",
    "Feat2=np.array(Feature_vectors_sig2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f514ade2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9058823529411765"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separate data into train and test\n",
    "X_train2, X_test2, y_train2, y_test2=train_test_split(Feat2,labels2,test_size=0.33)\n",
    "# Train model on X_train\n",
    "clf=RandomForestClassifier().fit(X_train2,y_train2)\n",
    "\n",
    "#Predict Labels of X_test\n",
    "y_predicted2=clf.predict(X_test2)\n",
    "\n",
    "\n",
    "#Compare predicted labels with y\n",
    "accuracy_score(y_test2,y_predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12123088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AD vs MCI classification\n",
    "not1=[]\n",
    "for individual, individual_data in newdata.groupby(\"Individual\"):\n",
    "    if ( not (individual_data.iloc[:,1]==1).any()) :\n",
    "        not1.append(individual)\n",
    "        \n",
    "newdata1=newdata[newdata[\"Individual\"].isin(not1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06c2bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=[]\n",
    "Feature_vectors_sig1=list()\n",
    "for individual, individual_data in newdata1.groupby(\"Individual\"):\n",
    "    individual_timeseries=individual_data.iloc[:,[2,3,4,5]].to_numpy()\n",
    "    individual_signature=esig.stream2sig(individual_timeseries,2)[1:]\n",
    "    individual_baseline=individual_timeseries[0][[1,2,3]]\n",
    "    individual_feature_vector=np.concatenate([individual_baseline,individual_signature])\n",
    "    Feature_vectors_sig1.append(individual_feature_vector)\n",
    "    labels1.append(individual_data.iloc[0,1])\n",
    "Feat1=np.array(Feature_vectors_sig1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82a31103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separate data into train and test\n",
    "X_train1, X_test1, y_train1, y_test1=train_test_split(Feat1,labels1,test_size=0.33)\n",
    "# Train model on X_train\n",
    "clf=RandomForestClassifier().fit(X_train1,y_train1)\n",
    "\n",
    "#Predict Labels of X_test\n",
    "y_predicted1=clf.predict(X_test1)\n",
    "\n",
    "\n",
    "#Compare predicted labels with y\n",
    "accuracy_score(y_test1,y_predicted1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
