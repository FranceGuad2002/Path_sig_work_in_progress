{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d935f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import iisignature as iis\n",
    "from gtda.homology import FlagserPersistence\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "import gudhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2499f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead_matrix_1(mv_time_series):\n",
    "    N=mv_time_series.shape[1]\n",
    "    sig=iis.sig(mv_time_series,2)\n",
    "    S=sig[N:].reshape(N,N)\n",
    "    L=(S-S.T)/2\n",
    "    return L\n",
    "def lead_matrix_2(mv_time_series):\n",
    "    N=mv_time_series.shape[1]\n",
    "    sig=iis.sig(mv_time_series,2)\n",
    "    S=sig[N:].reshape(N,N)\n",
    "    L=(S-S.T)/2\n",
    "    a=np.max(np.abs(L))\n",
    "    L2=L/a\n",
    "    return L2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be242630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead_tensor_1(mv_time_series):\n",
    "    N=mv_time_series.shape[1]\n",
    "    sig=iis.sig(mv_time_series,3)\n",
    "    l=N+N*N\n",
    "    S=sig[l:].reshape(N,N,N)\n",
    "    T=(S-S.transpose((0,2,1))+S.transpose((2,0,1))-S.transpose((2,1,0))+S.transpose((1,2,0))-S.transpose((1,0,2)))/6\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73e89809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_undirected(L):\n",
    "    l=L.shape[0]\n",
    "    a=np.max(np.abs(L))\n",
    "    ADM=a*np.ones((l,l))-a*np.identity(l)-np.abs(L)\n",
    "    VR= VietorisRipsPersistence(metric=\"precomputed\")\n",
    "    dgm= VR.fit_transform([ADM])\n",
    "    return dgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c209da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_directed(L):\n",
    "    l=L.shape[0]\n",
    "    a=np.max(np.abs(L))\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            if L[j,i]<0:\n",
    "                L[j,i]=0\n",
    "                \n",
    "    ADM=a*np.ones((l,l))-a*np.identity(l)-L            \n",
    "    dgm=FlagserPersistence().fit_transform([ADM])\n",
    "    return dgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "862e6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertex_edge_tensor_cofl(mv_time_series):\n",
    "    N=mv_time_series.shape[1]\n",
    "    l=mv_time_series.shape[0]\n",
    "    T=np.zeros((N,N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                if ((not (i==j)) and (not (i==k)) and (not (j==k))):\n",
    "                    store=np.zeros((l,2))\n",
    "                    store[:,1]=mv_time_series[:,j]*mv_time_series[:,k]\n",
    "                    store[:,0]=mv_time_series[:,i]\n",
    "                    sig=iis.sig(store,2)\n",
    "                    area_cofl=(sig[3]-sig[4])/2\n",
    "                    T[i,j,k]=area_cofl\n",
    "                    \n",
    "    return T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01bd722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertex_edge_tensor_conv(mv_time_series):\n",
    "    N=mv_time_series.shape[1]\n",
    "    l=mv_time_series.shape[0]\n",
    "    T=np.zeros((N,N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                if ((not (i==j)) and (not (i==k)) and (not (j==k))):\n",
    "                    store=np.zeros((l,2))\n",
    "                    store[:,1]=np.convolve(mv_time_series[:,j],mv_time_series[:,k],\"same\")\n",
    "                    store[:,0]=mv_time_series[:,i]\n",
    "                    sig=iis.sig(store,2)\n",
    "                    area_conv=(sig[3]-sig[4])/2\n",
    "                    T[i,j,k]=area_conv\n",
    "                    \n",
    "    return T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33555002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filtration_2(Lead_matrix, Lead_tensor,indifferent_value):\n",
    "    \n",
    "\n",
    "    # Creating the list of simplicial complex with all the edges and triangles\n",
    "    sc=gudhi.SimplexTree()\n",
    "    list_simplices = []\n",
    "    N=Lead_matrix.shape[0]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if np.abs(Lead_matrix[i,j])<indifferent_value:\n",
    "                Lead_matrix[i,j]=0\n",
    "            for k in range(N):\n",
    "                if np.abs(Lead_tensor[i,j,k])<indifferent_value:\n",
    "                    Lead_tensor[i,j,k]=0\n",
    "\n",
    "        \n",
    "\n",
    "        # Selecting the extremal weight between edges and triplets. It will be assigned to all the nodes (i.e. nodes enter at the same instant)\n",
    "    m_weight = np.max([np.ceil(np.max(np.abs(Lead_matrix))), np.ceil(np.max(np.abs(Lead_tensor)))])\n",
    "    # Adding all the nodes from the beginning with the same weights\n",
    "    for i in range(N):\n",
    "        list_simplices.append(([i], m_weight))\n",
    "\n",
    "        # Adding the edges:\n",
    "        # Also, modify the signs of the weights to correct the z-score so that: if the edge signal is fully coherent, then assign a positive sign, otherwise negative\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            if (not i==j):\n",
    "                weight=np.abs(Lead_matrix[i,j])\n",
    "                list_simplices.append(([i,j], weight))\n",
    "\n",
    "        # Adding the triplets\n",
    "        # Here I modify the signs of the weights, if it is fully coherent I assign a positive sign, otherwise negative\n",
    "    for i in range(N):\n",
    "        for j in range(i,N):\n",
    "            for k in range(j,N):\n",
    "                if ((not (i==j)) and (not(j==k)) and (not(i==k))):\n",
    "                    weight=np.abs(Lead_tensor[i,j,k])\n",
    "                    list_simplices.append(([i,j,k], weight))\n",
    "\n",
    "    sorted_simplices = sorted(list_simplices, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Remove the violations\n",
    "    list_violating_triangles = []\n",
    "    set_simplices = set()\n",
    "    counter = 0\n",
    "    triangles_count = 0\n",
    "    violation_triangles = 0\n",
    "    violation_triangles_negativeterms = 0\n",
    "\n",
    "        # Loop over the sorted simplices, and flippling the sign of all the weights (so that the points in the persistence diagram are above the diagonal)\n",
    "    for index, i in enumerate(sorted_simplices):\n",
    "        simplices, weight = i\n",
    "\n",
    "            # If the current simplex is an edge or a node, then I will immediately include it\n",
    "        if len(simplices) <= 2:\n",
    "            sc.insert(simplices, -weight)\n",
    "            set_simplices.add(tuple(simplices))\n",
    "            counter += 1\n",
    "        else:\n",
    "        # If the current simplex is a triplet, I check whether all the sub-simplices have been included.\n",
    "            flag = 0\n",
    "            n0=simplices[0]\n",
    "            n1=simplices[1]        \n",
    "            n2=simplices[2]\n",
    "            if (n0,n1) in set_simplices:\n",
    "                flag=flag+1\n",
    "            if (n1,n2) in set_simplices:\n",
    "                flag=flag+1\n",
    "            if (n0,n2) in set_simplices:\n",
    "                flag=flag+1\n",
    "\n",
    "                # If all the sub-simplices already belong to the set, then I add it in the filtration\n",
    "            if flag == 3:\n",
    "                set_simplices.add(tuple(simplices))\n",
    "                sc.insert(simplices, -weight)\n",
    "                counter += 1\n",
    "                triangles_count += 1\n",
    "            else:\n",
    "                violation_triangles += 1\n",
    "                list_violating_triangles.append((simplices, np.abs(weight), 3 - flag))\n",
    "\n",
    "# Fraction of positive triangle discarderd (a.k.a. the hyper coherence)\n",
    "    hyper_coherence = (1.0 * violation_triangles) /(triangles_count + violation_triangles)\n",
    "        \n",
    "    return(sc, list_violating_triangles,hyper_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dccac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diagram_directly_2(mv_time_series, indifferent_value):\n",
    "    L=lead_matrix_1(mv_time_series)\n",
    "    T=lead_tensor_1(mv_time_series)\n",
    "    f=create_filtration_2(L,T,indifferent_value)\n",
    "    sc=f[0]    \n",
    "    dgm=sc.persistence()\n",
    "    return dgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e14da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_coherence(mv_time_series,indifferent_value):\n",
    "    L=lead_matrix_1(mv_time_series)\n",
    "    T=lead_tensor_1(mv_time_series)\n",
    "    f=create_filtration_2(L,T,indifferent_value)\n",
    "    hyp=f[2]\n",
    "    return hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e227651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diagram_directly_3(mv_time_series, indifferent_value):\n",
    "    L=lead_matrix_1(mv_time_series)\n",
    "    T=lead_tensor_1(mv_time_series)\n",
    "    f=create_filtration_2(L,T,indifferent_value)\n",
    "    sc=f[0]\n",
    "    hyp=f[2]\n",
    "    dgm=sc.persistence()\n",
    "    return dgm,hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01238be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_gu_ad(dgm):\n",
    "    total_0=0\n",
    "    total_1=0\n",
    "    l_0=[]\n",
    "    l_1=[]\n",
    "    l=len(dgm)\n",
    "    for i in range(l):\n",
    "        if dgm[i][0]==1:\n",
    "            if (not (dgm[i][1][1]==np.inf)):\n",
    "                length=dgm[i][1][1]-dgm[i][1][0]\n",
    "                total_1=total_1+length\n",
    "                l_1.append(length)\n",
    "        if dgm[i][0]==0:\n",
    "            if (not (dgm[i][1][1]==np.inf)):\n",
    "                length=dgm[i][1][1]-dgm[i][1][0]\n",
    "                total_0=total_0+length\n",
    "                l_0.append(length)\n",
    "\n",
    "    log_l_1=np.log(np.array(l_1)/total_1)\n",
    "    log_l_0=np.log(np.array(l_0)/total_0)\n",
    "    prod_1=log_l_1*(np.array(l_1)/total_1)\n",
    "    prod_0=log_l_0*(np.array(l_0)/total_0)\n",
    "    S_1=-np.sum(prod_1)\n",
    "    S_0=-np.sum(prod_0)\n",
    "    return S_0,S_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1a6d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_vector(time_series,indifference_value,length):\n",
    "    l=time_series.shape[0]\n",
    "    N=time_series.shape[1]\n",
    "    h=np.modf(l/length)[1]\n",
    "    hyp_ts=[]\n",
    "    for i in range(1,length+1):\n",
    "        sub_ts=time_series[:np.int64(h)*i,:]\n",
    "        hyp=hyper_coherence(sub_ts,indifference_value)\n",
    "        hyp_ts.append(hyp)\n",
    "    return hyp_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a15f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_mat(path_single_file):\n",
    "    file_to_open = path_single_file\n",
    "    data = sio.loadmat(file_to_open)\n",
    "    key_data = list(data.keys())[-1]\n",
    "    data = data[key_data]\n",
    "    return(data)\n",
    "\n",
    "def load_data_mat_bipolar(path_single_file):\n",
    "    file_to_open = path_single_file\n",
    "    data = sio.loadmat(file_to_open)\n",
    "    key_data = list(data.keys())[-2]\n",
    "    data = data[key_data]\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e0f2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(r, x):\n",
    "    return (1 - r * (x**2))\n",
    "    # alternative  chaotic map\n",
    "    # return(4*x*(1-x))\n",
    "\n",
    "\n",
    "# See book of Kaneko for parameters of eps and/or r to have different regimes\n",
    "# or https://en.wikipedia.org/wiki/Coupled_map_lattice for notable regimes\n",
    "\n",
    "\n",
    "# Generate couple map lattice according to this equation: x_i^t= (1-\\eps)f[x_i^{t-1}] + \\eps/order \\sum_{j in \\neighbours} f[x_j]^{t-1}\n",
    "def generate_couple_map(T, N, epsilon, transient_time, r, order=2):\n",
    "    series = {}\n",
    "\n",
    "    # Filing the dictionary with N initial random values\n",
    "    for index_series in range(0, N):\n",
    "        s = random.random()\n",
    "        series[index_series] = [s]\n",
    "\n",
    "    # Generate the coupled maps for a length of size T (yet, we discard the first transient_time elements to remove the transient)\n",
    "    for i in range(1, T + transient_time + 1):\n",
    "        for index_series in range(0, N):\n",
    "            order_k_term = compute_neighbours(N, series, epsilon, index_series, i - 1, r, order)\n",
    "            new_point = (1 - epsilon) * logistic(r,series[index_series][i - 1]) + order_k_term\n",
    "            series[index_series].append(new_point)\n",
    "    return(series)\n",
    "\n",
    "\n",
    "\n",
    "def compute_neighbours(N, series, epsilon, index_series, i, r, order=2):\n",
    "    eps_overN = epsilon * (1 / order)\n",
    "    term_left_right = int(order / 2)\n",
    "\n",
    "    term = 0\n",
    "    # Sum over the left neighbors with periodic boundary conditions\n",
    "    for s in range(1, term_left_right + 1):\n",
    "        term += logistic(r, series[(index_series - s) % N][i])\n",
    "\n",
    "    # Sum over the right neighbors with periodic boundary conditions\n",
    "    for s in range(1, term_left_right + 1):\n",
    "        term += logistic(r, series[(index_series + s) % N][i])\n",
    "\n",
    "    # if order is odd, then take the neighbors in an asymmetric way, int(order/2) on the left, int(order/2)+1 on the right\n",
    "    if order % 2 == 1:\n",
    "        s = term_left_right + 1\n",
    "        term += logistic(r, series[(index_series + s) % N][i])\n",
    "\n",
    "    return(term * eps_overN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ac3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
